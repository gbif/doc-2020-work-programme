== Priority 2: Enhance Biodiversity Information Infrastructure

****
Provide leadership, expertise and tools to support the integration of all biodiversity information as an interconnected digital knowledgebase.
****

=== Activity 2a: Modernize data standards

==== Tasks
[lowerroman]
. Promote development of a shared domain model for sharing and linking all components of biodiversity information
. Lead a review of the Darwin Core vocabulary and associated extensions to ensure consistency and full alignment with a shared domain model
. Explore opportunities to increase accessibility of biodiversity data through evolution of Darwin Core Archive formats to W3C CSV on the Web formats
. Explore models to enable GBIF and other biodiversity infrastructures to deliver comprehensive global catalogues of instances of key data classes
. Improve management of trait data of relevance to GBIF

==== 2019 Progress

The alliance for biodiversity knowledge is beginning to act as a platform to engage the biodiversity informatics community around community standards. GBIF is active in numerous significant existing networks that seek to address these needs in parallel. This work is ongoing into 2020 and beyond.

At the core of this is the Biodiversity Information Standards (TDWG) community. GBIF continues to participate in open TDWG discussions around https://doi.org/10.3897/biss.3.37491[ABCD/DwC alignment] and recognize many other complementary activities and discussions on a biodiversity knowledge graph by partners. Notably:

*	Through Plazi taxonomic treatment data are becoming connected 
*	Pensoft have piloted the https://doi.org/10.3390/publications7020038[OpenBioDiv system] to better connect information in scholarly publications with specimens
*	The https://ozymandias-demo.herokuapp.com[Ozymandias biodiversity knowledge graph pilot] by Rod Page

Proposed SYNTHESYS+ workshops are to focus on modernizing standards activities that seek to improve the representation of information such as 

. Citation and Provenance models for collections data, including links between specimens, individuals and literature and their relationships to DOI, ORCIDs and other important open identifier issuing systems
. Information model for representing Natural History Collections including the TDWG natural Collections Descriptions standard and integrations with other collections catalogues
. Information model for representing Specimens; reviewing collection management systems and developing an information model with data classes representing all the asset types and linked information of importance in building a fully interconnected virtual natural history collection

During 2019, the informatics team has continued the redesign and implementation of GBIF data ingestion pipelines. Data growth required significant changes to the backend to ensure GBIF can 1) continue to grow with data volume, 2) accommodate new feature deployments that require full data reprocessing, and 3) look to expand data content types.

===== 2019 Participant contributions

* *Tecala*: Did something really important.

==== 2020 Work items

*	Modernizing data standards is a continuous Work Programme activity for a global infrastructure like GBIF. During 2020 we will focus on advancing and refining data models for Collections, Taxonomic Treatments, Sampling Events, Organisms, Specimens, Organisms, Citations and the linkages between them.
*	Provide a set of data-exchange profiles for sharing data within GBIF that conforms with a unified information model that includes both existing and new standards as well as the necessary controlled vocabularies.
*	Redesign the GBIF Integrated Publishing Toolkit (IPT) to support these profiles and to address infrastructure needs, such as the ability to support local installations or GBIF-hosted solution. If funds allow, €50,000 for an external contractor.
*	Provide documentation for the data model and for the associated services offered through GBIF.org. 
*	Review and redesign GBIF data management system to accommodate the unified information model as part of data ingestion, quality control and processing where necessary.
*	Continue technical discussions with other data aggregators to seek closer alignment in practice and, as far as possible, implementation of aggregation and indexing processes.
*	Demonstrate improvements of information in GBIF.org and hosted national portals in specimen-level information, links to material citations, and links between specimens and sequence data from sources such as BOLD.
*	Explore approaches for adding a phylogenetic/evolutionary dimension to the GBIF taxonomic backbone. Pilot phylogenetic browsing capabilities of occurrence data.
*	Open discussion with GB participants to provide project funders with an overview of the resulting value relating to their investment (e.g. data mobilization, publications).
*	In collaboration with international partners, explore the desirability and scope of “catalogue services” that are targeted specifically at physical specimen collections. Examples could include displaying duplicate or derived specimens across collections, type information, citations in taxonomic treatments and trait data.
*	Explore options for displaying occurrence data from long-term sampling sites, piloting with projects like BIOSCAN 2 and/or Norwegian ecological datasets.

===== 2020 Participant plans

* *Tecala*: Do something big.

==== Rationale

The GBIF network participants are able to reliably exchange data thanks to their adherence to a set of standards. As GBIF looks to grow in capability, enable exchange of richer content and improve the quality of data, the standards must be revised and evolve accordingly.

Current standards adopted by GBIF are not yet adequate to accommodate the needs expressed by many potential and existing data publishers. Weaknesses in the model have led to ambiguous or over-complex data representations and unclear documentation, leading to difficulties in data integration and use. The main issues relate to uncertainties around the use of Darwin Core record types, the basisOfRecord element, and the use of Core and Extension vocabularies. Reviewing and updating the core domain model, tightening up the vocabularies and documentation and adopting more robust exchange standards will result in an easier to use, and a wider reaching GBIF data exchange network.

==== Approach

GBIF will work with TDWG and other key stakeholders to review existing solutions for a common domain model, working towards agreement on a model to adopt with key partners. This conceptual model should cover the main components of biodiversity information (the domain “classes” such as Specimen, Collection, TaxonName, TaxonConcept, Publication, Sequence) and document the mandatory and recommended properties expected for each component and the vocabularies that should control the properties. A review of existing vocabularies and their current uses will be undertaken and revisions and new vocabularies will be proposed where necessary. A revision of the Darwin Core Archive mechanism and supporting tools, such as the publishing toolkit (IPT) and the data validator, will be undertaken to accommodate the richer content model and the new recommendations from the W3C CSV on the Web working group. GBIF should continue discussions with other key global biodiversity data infrastructures to develop comprehensive catalogues to support discovery and normalisation of instances of the most critical domain classes (particularly TaxonName, TaxonConcept, Collection, Specimen, TaxonOccurrence).

In addition to completing this knowledge graph, GBIF should be equipped to link between people, datasets, cited use and funding agencies through the correct attribution chains using e.g. Digital Object Identifiers (DOIs) and Open Researcher and Contributer ID (ORCID) as potential mechanisms.
